# 개념정리
## Expectations of Standard Random Variables (표준확률변수의 기대값)
- 확률변수가 표준확률변수일 때, 기대값을 구하는 방법
1. Uniform(균등 분포) on ${a, a+1, ... , b} : E[X] = (a+b)/2$
2. Bernoulli(베르누이 분포): $E[X] = (1-p)*0+p*1=p$
3. Binomial(이항 분포): $E[X] = np$
4. Geometric(기하 분포): $E[X] = 1/p$
5. Poisson(포아송 분포): $E[X] = \lambda$

### Uniform Expectation (균등분포의 기대값 증명)
- $E[X] = (b+a)/2$
<Math>

```math
E[X] = \sum_{k=a}^{b} kP(X = k) \\
= \sum_{k=a}^{b} k \times \frac{1}{b - a + 1} \\
= \frac{1}{b - a + 1} \sum_{k=a}^{b} k \\
= \frac{1}{b - a + 1} \frac{(a + b)(b - a + 1)}{2} \\
= \frac{a + b}{2}
```
</Math>

- 설명
	- $E[X] = \frac{a + b}{2}$
	- $E[X] = \frac{1}{b - a + 1} \frac{(a + b)(b - a + 1)}{2}$
	- $E[X] = \frac{1}{b - a + 1} \sum_{k=a}^{b} k$
	- $E[X] = \sum_{k=a}^{b} k \times \frac{1}{b - a + 1}$
	- $E[X] = \frac{a + b}{2}$

### Poisson Expectation (포아송분포의 기대값 증명)
- $E[X] = \lambda$
<Math>

```math
E[X] = \sum_{k=0}^{\infty} k \cdot \frac{e^{-\lambda} \lambda^k}{k!} \\
= \lambda \sum_{k=1}^{\infty} \frac{k \cdot e^{-\lambda} \lambda^{k-1}}{k!} \\
= \lambda \sum_{k=1}^{\infty} \frac{e^{-\lambda} \lambda^{k-1}}{(k - 1)!} \\
= \lambda \left(P(X = 0) + P(X = 1) + P(X = 2) + \ldots \right) \\
= \lambda

```
</Math>

- 설명
	- $E[X] = \lambda \left(P(X = 0) + P(X = 1) + P(X = 2) + \ldots \right)$
	- $E[X] = \lambda \sum_{k=1}^{\infty} \frac{e^{-\lambda} \lambda^{k-1}}{(k - 1)!}$
	- $E[X] = \lambda \sum_{k=1}^{\infty} \frac{k \cdot e^{-\lambda} \lambda^{k-1}}{k!}$
	- $E[X] = \lambda \sum_{k=0}^{\infty} k \cdot \frac{e^{-\lambda} \lambda^k}{k!}$
	- $E[X] = \lambda$
### Geometric Expectation (기하분포의 기대값 증명)
- $E[X] = 1/p$
<Math>

```math
E[X] = \sum_{k=1}^{\infty} k \cdot (1 - p)^{k-1} \cdot p \\
= \sum_{k=1}^{\infty} (1 - p)^{k-1} \cdot p + \sum_{k=1}^{\infty} (k - 1) \cdot (1 - p)^{k-1} \cdot p \\
= 1 + (1 - p) \sum_{k=2}^{\infty} (k - 1) \cdot (1 - p)^{k-2} \cdot p \\
= 1 + (1 - p) \left( 1 \times P(X = 1) + 2 \times P(X = 2) + 3 \times P(X = 3) + \ldots \right) \\
= 1 + (1 - p) E[X] \\
\text{and so } E[X] = \frac{1}{p}
```
</Math>

- 설명
	- $E[X] = 1 + (1 - p) E[X]$ 에서 $E[X]$를 구하면 $E[X] = \frac{1}{p}$
	- $E[X] = 1 + (1 - p) E[X]$ 에서 $E[X]$를 구하는 방법은 다음과 같다.
		- $E[X] = 1 + (1 - p) \sum_{k=2}^{\infty} (k - 1) \cdot (1 - p)^{k-2} \cdot p$
		- $E[X] = 1 + (1 - p) \left( 1 \times P(X = 1) + 2 \times P(X = 2) + 3 \times P(X = 3) + \ldots \right)$
		- $E[X] = 1 + (1 - p) E[X]$

## Variance of Standard Random Variables (표준확률변수의 분산)
- 확률변수가 표준확률변수일 때, 분산을 구하는 방법
### 번역
표준 확률 변수의 분산을 나타낸다.

- Bernoulli(베르누이 분포): $var[X] = p(1 - p)$
- Binomial(이항 분포): $var[X] = np(1 - p)$
- Geometric(기하 분포): $var[X] = (1-p) / p^2$
- Uniform(균등 분포): $var[X] = (b-a+1)^2 - 1 / 12$
- Poisson(포아송 분포): $var[X] = λ$

# 예제
## 예제 1
### 문제
- 당신의 확률론 수업에 300명의 학생이 있고, 각 학생이 다른 학생과 독립적으로 A를 받을 확률이 1/3이다. A를 받는 학생들의 기대 수는 어떻게 될까?
- i번째 학생이 A를 받으면 Xi = 1, 그렇지 않으면 0이다.
### 답
$X_i$: Bernoulli Random Variable
$P(X_i = 1) = 1/3, P(X_i = 0) = 2/3$

각 $X_1, X_2, ..., X_n$은 **Bernoulli Random Variable**이며 $E[X_i] = p = 1/3$이다.
분산 $var[X_i] = \underline{p(1 - p)} = \underline{1/3 * 2/3} = 2/9$
그들의 합 $X = X_1 + X_2 + ... + X_n$은 A를 받는 학생들의 수이며, n번의 독립 시행에서 '성공'의 수이다.
이것은 **Binomial Random Variables인** $n$과 $p$의 매개변수를 가진 이항 분포이다.
$\therefore E[X] = ΣE[Xi] = Σp = \underline{np} = \underline{300 * 1/3} = 100$이다.

### 추가 설명
이 예시에서 사용된 $X_1, X_2, ..., X_n$ 변수들은 베르누이 시행의 결과를 나타낸다.
베르누이 시행은 성공 또는 실패의 두 가지 결과만을 가진다.
이 경우 300명의 학생 각각이 A를 받을 확률이 독립적으로 1/3이므로, 베르누이 시행의 성공 확률 p는 1/3이다.
이항 분포의 기대값 공식을 사용하여, 전체 학생들 중 A를 받는 기대 학생 수를 계산할 수 있다.
이 때 n은 전체 학생 수인 300이고, p는 성공 확률인 1/3이므로 $np = 300 * (1/3) = 100$이 된다.
즉, 이 확률론 수업에서 평균적으로 100명의 학생이 A를 받을 것으로 기대할 수 있다.