## 확률 변수의 독립 (Independence of Random Variables)
> 두 확률 변수 $X$와 $Y$가 서로 독립일 때,
> $p_{X,Y}(x, y) = p_X(x) \cdot p_Y(y)\;\;\; \forall x, y$

독립은 다음과 같은 조건과 동등하다.
$p_{X, Y}(x|y) = p_X(x)\;\;\; \forall y \text{ with } p_Y(y) > 0 \text{ and } \forall x$
conditional PMF = marginal PMF ($X$와 $Y$가 서로 독립일 때)

### 예제 (확률 변수의 독립)
#### 문제
12개의 공정한 6면체 주사위를 던진다.
$X$는 '1'이 나온 개수이고 $Y$는 '6'이 나온 개수라고 하자.
$X$와 $Y$는 독립인가?

#### 해결
> $P(X=12, Y=12) = 0 \neq P(X=12) \cdot P(Y=12)$ 임을 증명

$X, Y$: binomial random variable (n = 12, p = 1/6)
$P(X = k) = \binom{12}{k} \left(\frac{1}{6}\right)^k \left(\frac{5}{6}\right)^{12-k}$
$P(X = 12) = \left(\frac{1}{6}\right)^{12}$
$P(Y = 12) = \left(\frac{1}{6}\right)^{12}$

답: $X$와 $Y$는 독립이 아니다.

## 독립 변수의 기대값 (Expectation of Independent Random Variables)
> $X$와 $Y$가 서로 독립이면, $E[XY] = E[X] \cdot E[Y]$이다.

### 증명
$E[XY] = \sum_{x}\sum_{y}xy\cdot p_{X,Y}(x, y) \\
= \sum_{x}\sum_{y}xy\cdot p_X(x)\cdot p_Y(y) \\
= \sum_{x}xp_X(x)\sum_{y}yp_Y(y) \\
= E[X] \cdot E[Y]$

### 예제 (독립 변수의 기대값)
#### 문제
$X$와 $Y$가 다음과 같은 결합 확률 질량 함수(PMF)를 가진다고 가정하자:
| $X$ \\ $Y$ | -1 | 0 | 1 |
| --- | --- | --- | --- |
| 0 | 0 | $\frac{1}{2}$ | 0 |
| 1 | $\frac{1}{4}$ | 0 | $\frac{1}{4}$ |

$E[X]$, $E[Y]$, $E[XY]$를 구하라.

#### 해결
주변 분포(marginal distribution)를 구하고, 독립인지 확인한다.
$E[X] = \sum xP_X(x) = 0 \cdot \frac{1}{2} + 1 \cdot \frac{1}{2} = \frac{1}{2}$
$E[Y] = \sum yP_Y(y) = -1 \cdot \frac{1}{4} + 0 \cdot \frac{1}{2} + 1 \cdot \frac{1}{4} = 0$
$E[XY] = E[X] \cdot E[Y] = \frac{1}{2} \cdot 0 = 0$

**답**: $E[X] = \frac{1}{2}$, $E[Y] = 0$, $E[XY] = 0$
$X, Y$는 독립이다.

## 독립 변수의 분산 (Variance of Independent Random Variables)
> 독립인 두 변수 $X, Y$가 $Z = X + Y$를 만족할 때, $Var(Z) = Var(X) + Var(Y)$이다.

### 증명
$Var(Z) = E[(X+Y-E[X+Y])^2]\\
= E[(X+Y-E[X]-E[Y])^2]\\
= E[((X-E[X]) + (Y-E[Y]))^2] \\
= E[(X-E[X])^2] + 2E[(X-E[X])(Y-E[Y])] + E[(Y-E[Y])^2] \\
= Var(X) + 0 + Var(Y)$

($2E[(X-E[X])(Y-E[Y])]  = \\
E[XY - XE[Y] - YE[X] + E[X]E[Y]] = \\
E[XY] - E[X]E[Y] - E[Y]E[X] + E[X]E[Y] = 0$)

### 예제 (독립 변수의 분산)
#### 문제
$X$와 $Y$가 독립이며 $\text{Var}(X) = 3$이고 $\text{Var}(Y) = 5$라고 가정하자.
다음을 구하시오:
1. $\text{Var}(X + Y)$
2. $\text{Var}(3X + 4)$
3. $\text{Var}(X + X)$
4. $\text{Var}(X + 3Y)$

#### 해결
1. $\text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y) = 3 + 5 = 8$
2. $\text{Var}(3X + 4) = 3^2\text{Var}(X) = 9 \cdot 3 = 27$
3. $\text{Var}(X + X) = 2^2\text{Var}(X) = 4 \cdot 3 = 12$
4. $\text{Var}(X + 3Y) = \text{Var}(X) + 3^2\text{Var}(Y) = 3 + 9 \cdot 5 = 48$

## 요약 (Summary)
두 확률 변수 $X$와 $Y$가 서로 독립이면, $p_{X,Y}(x, y) = p_X(x) \cdot p_Y(y)$이다.
두 확률 변수 $X$와 $Y$가 서로 독립이면, $E[XY] = E[X] \cdot E[Y]$이다.
두 확률 변수 $X$와 $Y$가 서로 독립이면, $Var(X + Y) = Var(X) + Var(Y)$이다.

## 추가 문제
#### 문제
$X$와 $Y$가 독립적이며 동일하게 분포된 기하 확률 변수라고 가정하자.
여기서 매개변수는 $p$이다.
다음을 증명하시오:
$P(X = i \mid X + Y = n) = \frac{1}{n-1}, \quad i = 1, \ldots, n-1$

#### 해결
$P(X = i \mid X + Y = n)$는 $n$번째 던짐에서 두 번째로 앞면이 나왔을 때, $i$번째 던짐에서 첫 번째로 앞면이 나왔을 확률로 해석할 수 있다.
직관적으로 $n$번째 던짐에서 두 번째로 앞면이 나온 경우, 첫 번째 앞면이 $1$에서 $n-1$사이의 어떤 던짐에서 나왔을 가능성이 동일하다.
이를 정확히 수학적으로 증명하기 위해 다음을 고려하자:
$$ P(X = i \mid X + Y = n) = \frac{P(X = i \text{ and } X + Y = n)}{P(X + Y = n)} = \frac{P(X = i)P(Y = n - i)}{P(X + Y = n)} $$
또한, $P(X = i) = p(1-p)^{i-1}$ ($i \geq 1$)이고, $P(Y = n - i) = p(1-p)^{n-i-1}$ ($n - i \geq 1$)이다.
따라서, $P(X = i)P(Y = n - i) = p^2(1 - p)^{n-2}$ ($i = 1, \ldots, n-1$)이고, 그 외의 경우는 0이다.
따라서, $P(X = i \mid X + Y = n) = P(X = j \mid X + Y = n)$는 $i$와 $j$가 $1$에서 $n-1$사이의 어떤 값이든 동일하다.
$P(X = i \mid X + Y = n) = \frac{1}{n-1}, \quad i = 1, \ldots, n-1$